# Toxic-Comment-Multilabel-Classification

This project focuses on creating and deploying a machine learning model for the classification of toxic comments using a multilabel classification approach. The goal is to automatically identify and classify comments with various types of toxicity, including hate speech, harassment, and profanity, among others. The project uses Natural Language Processing (NLP) techniques such as TF-IDF and advanced models like Random Forest and BERT for classification.

The model is trained on a large dataset sourced from the Jigsaw Toxic Comment Classification Challenge, and the evaluation includes key metrics like precision, recall, and F1-score. To handle data imbalance, techniques like MLSMOTE and manual oversampling are applied. The final model is deployed on a web platform using Flask, making it easy for users to submit comments for toxicity analysis in real-time. This deployment allows the system to identify multiple toxic labels for a single comment, providing a practical solution for moderating online content automatically.
